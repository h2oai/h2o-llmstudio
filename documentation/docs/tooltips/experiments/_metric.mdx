Defines the metric to evaluate the model's performance. 

We provide several metric options for evaluating the performance of your model. The options depend on the selected Problem Type:

Causal Language Modeling, DPO Modeling, Sequence to Sequence Modeling
- In addition to the BLEU and the Perplexity score, we offer GPT metrics that utilize the OpenAI API to determine whether
the predicted answer is more favorable than the ground truth answer.
- To use these metrics, you can either export your OpenAI API key as an environment variable before starting LLM Studio,
or you can specify it in the Settings Menu within the UI.

Causal Classification Modeling
- AUC: Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC).
- Accuracy: Compute the accuracy of the model.
- LogLoss: Compute the log loss of the model.
