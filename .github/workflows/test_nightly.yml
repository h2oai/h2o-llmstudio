name: Test Docker Image - Nightly

on:
  push:
    branches: [ main, docker_test ]
  pull_request:

jobs:
  test-ui-nightly:
    runs-on: [ self-hosted, gpu ]
    steps:
      # Pre-Action Cleanup
      - name: Clean workspace pre action
        run: |
          rm -rf ${{ github.workspace }}/*

      - name: Run the Docker Image
        run: |-
          mkdir llmstudio_mnt
          docker run --runtime=nvidia --shm-size=64g --init --rm -d -u `id -u`:`id -g` -p 10101:10101 -v /var/run/docker.sock:/var/run/docker.sock:ro -v $(pwd)/llmstudio_mnt:/home/llmstudio/mount gcr.io/vorvan/h2oai/h2o-llmstudio:nightly

      - uses: actions/checkout@v4
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: 3.10.11
      - name: Run UI Tests
        run: H2O_LLM_STUDIO_WORKDIR=/home/llmstudio/mount/ LOCAL_LOGIN=True PYTEST_BASE_URL=localhost:10101 make test-ui

      - name: Stop the Docker Image
        if: ${{ always() }}
        run: |-
          docker stop $(docker ps -q --filter ancestor=gcr.io/vorvan/h2oai/h2o-llmstudio:nightly)
      - name: Remove the Docker Image
        if: ${{ always() }}
        run: |-
          docker rmi gcr.io/vorvan/h2oai/h2o-llmstudio:nightly
      - name: Clean up dangling images
        if: ${{ always() }}
        run: |-
          docker image prune --force
          docker volume prune --force
          docker network prune --force
          docker container prune --force

      # Post-Action Cleanup
      - name: Clean workspace after action
        if: ${{ always() }}
        run: |
          rm -rf ${{ github.workspace }}/*
